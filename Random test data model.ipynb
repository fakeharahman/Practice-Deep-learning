{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=[]\n",
    "train_Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 56, 97, 75, 60, 92, 91, 80, 43, 82, 71, 53, 81, 36, 19, 43, 99, 38, 74, 24, 43, 89, 65, 88, 29, 87, 85, 18, 93, 83, 49, 98, 17, 30, 66, 98, 94, 73, 64, 98, 27, 77, 31, 69, 64, 41, 74, 78, 70, 98, 74, 67, 40, 85, 20, 98, 31, 79, 62, 98, 84, 69, 50, 96, 95, 16, 99, 86, 49, 48, 82, 79, 58, 53, 58, 28, 46, 76, 36, 48, 82, 62, 16, 85, 32, 44, 64, 25, 88, 100, 95, 87, 82, 50, 97, 32, 41, 97, 97, 72, 54, 82, 51, 72, 89, 91, 26, 31, 25, 90, 19, 69, 45, 46, 14, 90, 21, 18, 94, 33, 42, 47, 38, 68, 25, 88, 22, 43, 30, 22, 71, 100, 18, 76, 25, 89, 93, 78, 38, 43, 82, 14, 81, 80, 20, 74, 43, 70, 66, 51, 64, 70, 91, 96, 74, 75, 39, 40, 50, 58, 74, 68, 79, 43, 80, 74, 67, 92, 35, 91, 95, 92, 50, 97, 63, 69, 89, 73, 87, 37, 72, 24, 15, 65, 56, 85, 81, 41, 14, 56, 92, 25, 85, 73, 78, 92, 60, 29, 14, 43, 47, 100, 88, 77, 52, 89, 82, 43, 62, 65, 90, 29, 80, 76, 84, 91, 36, 91, 99, 67, 57, 15, 34, 55, 81, 22, 70, 16, 77, 19, 20, 73, 49, 95, 91, 73, 28, 23, 96, 60, 14, 55, 40, 82, 100, 41, 97, 68, 72, 37, 49, 31, 66, 27, 53, 15, 88, 74, 37, 15, 71, 40, 51, 35, 72, 51, 26, 25, 86, 43, 19, 47, 22, 27, 63, 64, 90, 43, 46, 24, 98, 35, 28, 37, 15, 96, 74, 76, 67, 89, 64, 77, 21, 84, 18, 99, 20, 23, 61, 74, 13, 84, 32, 95, 81, 48, 97, 95, 98, 60, 63, 62, 98, 87, 64, 56, 63, 65, 33, 86, 64, 97, 65, 82, 54, 38, 42, 41, 62, 75, 94, 79, 17, 44, 54, 100, 77, 93, 91, 41, 80, 18, 29, 99, 83, 40, 77, 66, 60, 83, 93, 68, 67, 74, 18, 38, 79, 81, 39, 60, 58, 15, 80, 71, 64, 80, 14, 84, 42, 87, 71, 18, 90, 76, 87, 32, 45, 100, 98, 19, 43, 79, 30, 58, 48, 96, 76, 66, 36, 73, 14, 81, 98, 100, 100, 32, 71, 59, 98, 86, 51, 47, 97, 45, 52, 95, 98, 89, 23, 69, 37, 51, 90, 68, 93, 20, 72, 72, 31, 92, 38, 82, 69, 17, 17, 45, 97, 92, 87, 30, 70, 86, 39, 53, 87, 18, 50, 25, 43, 85, 47, 61, 67, 82, 18, 39, 44, 81, 50, 15, 71, 87, 76, 76, 51, 86, 15, 55, 62, 24, 38, 71, 81, 98, 62, 32, 21, 51, 52, 17, 24, 39, 25, 70, 55, 29, 21, 83, 27, 64, 99, 34, 64, 42, 86, 53, 70, 99, 45, 68, 78, 38, 28, 34, 98, 31, 45, 39, 50, 23, 35, 23, 68, 41, 93, 75, 99, 97, 81, 100, 85, 67, 32, 49, 63, 41, 58, 90, 87, 72, 96, 31, 81, 34, 53, 71, 68, 54, 42, 34, 68, 93, 77, 81, 68, 63, 48, 97, 14, 100, 82, 15, 27, 37, 23, 72, 48, 74, 34, 85, 53, 43, 50, 90, 77, 20, 27, 45, 59, 58, 85, 59, 30, 59, 86, 17, 40, 69, 72, 65, 13, 64, 17, 34, 28, 19, 27, 38, 97, 81, 57, 30, 77, 34, 52, 27, 68, 30, 70, 34, 92, 54, 15, 58, 50, 75, 97, 98, 94, 75, 22, 45, 78, 84, 75, 98, 77, 60, 81, 97, 83, 89, 30, 42, 51, 91, 75, 16, 82, 86, 53, 86, 28, 83, 82, 33, 74, 97, 92, 97, 87, 98, 18, 81, 37, 60, 26, 14, 44, 72, 74, 54, 14, 31, 40, 44, 15, 56, 70, 14, 89, 22, 42, 86, 49, 92, 79, 87, 60, 96, 74, 21, 69, 79, 93, 27, 51, 65, 90, 90, 34, 46, 44, 60, 70, 81, 28, 56, 38, 20, 42, 16, 70, 56, 69, 52, 36, 47, 51, 91, 58, 31, 62, 80, 76, 59, 16, 32, 68, 86, 70, 24, 57, 99, 86, 71, 40, 30, 44, 43, 33, 48, 47, 98, 55, 75, 72, 76, 80, 26, 13, 28, 98, 62, 40, 34, 61, 78, 88, 73, 79, 96, 86, 82, 41, 72, 67, 79, 91, 99, 58, 85, 23, 24, 87, 48, 20, 40, 98, 28, 48, 44, 88, 71, 83, 97, 29, 71, 39, 13, 65, 93, 48, 72, 64, 57, 22, 70, 93, 70, 97, 43, 83, 22, 25, 37, 58, 65, 79, 51, 84, 60, 78, 64, 73, 75, 92, 93, 48, 100, 93, 96, 52, 80, 29, 75, 29, 65, 93, 13, 27, 65, 27, 93, 77, 39, 14, 93, 52, 88, 56, 50, 28, 13, 42, 56, 25, 70, 72, 76, 34, 20, 55, 73, 75, 74, 81, 51, 82, 85, 20, 56, 79, 56, 94, 100, 68, 92, 67, 67, 83, 40, 21, 89, 13, 42, 77, 97, 92, 100, 44, 68, 80, 78, 88, 98, 76, 24, 70, 45, 72, 78, 57, 76, 76, 81, 80, 25, 73, 93, 51, 48, 70, 100, 28, 67, 44, 69, 76, 66, 46, 89, 91, 67, 97, 32, 13, 74, 91, 82, 75, 25, 79, 52, 90, 73, 92, 14, 79, 60, 77, 36, 25, 94, 49, 19, 43, 85, 79, 100, 92, 46, 35, 52, 37, 37, 99, 46, 54, 44, 13, 18, 72, 82, 32, 19, 27, 83, 31, 18, 82, 22, 84, 32, 69, 17, 71, 23, 66, 78, 13, 52, 22, 46, 60, 90, 66, 96, 68, 14, 37, 68, 88, 64, 73, 68, 68, 81, 58, 67, 16, 62, 20, 32, 82, 81, 66, 87, 13, 97, 88, 71, 55, 69, 82, 99, 76, 23, 49, 84, 17, 92, 76, 90, 24, 54, 21, 66, 27, 21, 99, 73, 71, 70, 28, 85, 78, 54, 37, 29, 93, 80, 66, 15, 95, 72, 46, 94, 48, 83, 52, 96, 16, 36, 81, 88, 46, 29, 62, 42, 91, 69, 96, 84, 41, 73, 43, 99, 66, 15, 98, 24, 97, 46, 32, 42, 24, 68, 98, 70, 66, 72, 55, 100, 88, 52, 41, 39, 50, 55, 15, 58, 51, 51, 79, 52, 78, 97, 60, 19, 15, 43, 18, 83, 98, 84, 67, 53, 60, 45, 88, 23, 74, 99, 57, 80, 75, 44, 76, 100, 60, 36, 100, 67, 64, 58, 82, 97, 45, 20, 27, 55, 37, 93, 71, 52, 45, 17, 85, 71, 72, 60, 28, 92, 30, 47, 54, 62, 79, 40, 32, 49, 93, 34, 82, 40, 61, 86, 30, 89, 36, 51, 30, 92, 73, 47, 44, 30, 16, 75, 41, 32, 60, 89, 63, 75, 53, 23, 65, 76, 72, 75, 31, 87, 96, 18, 73, 39, 93, 39, 31, 37, 78, 61, 34, 89, 62, 15, 18, 35, 48, 85, 98, 84, 14, 48, 77, 76, 88, 92, 70, 94, 85, 65, 83, 55, 92, 49, 97, 64, 81, 76, 99, 15, 89, 86, 39, 76, 57, 35, 80, 57, 90, 39, 76, 45, 88, 36, 81, 48, 92, 18, 48, 65, 23, 57, 51, 75, 80, 92, 72, 80, 79, 62, 95, 14, 82, 63, 85, 98, 15, 64, 46, 47, 60, 86, 32, 22, 66, 79, 92, 25, 66, 41, 31, 72, 36, 31, 89, 30, 80, 80, 91, 75, 83, 52, 25, 46, 96, 72, 54, 57, 29, 20, 66, 89, 20, 41, 94, 56, 61, 79, 32, 36, 95, 75, 57, 65, 71, 98, 65, 91, 67, 29, 75, 77, 77, 60, 83, 54, 95, 24, 67, 70, 13, 59, 95, 34, 69, 19, 59, 37, 79, 81, 16, 98, 47, 29, 58, 96, 21, 64, 21, 27, 69, 98, 70, 74, 78, 84, 99, 95, 77, 62, 23, 39, 47, 62, 60, 88, 17, 61, 24, 95, 26, 82, 46, 90, 97, 89, 42, 75, 56, 30, 83, 78, 90, 83, 92, 77, 92, 39, 76, 22, 52, 48, 86, 26, 95, 30, 83, 89, 47, 89, 76, 50, 82, 26, 55, 75, 26, 90, 22, 26, 67, 37, 97, 23, 65, 67, 79, 44, 83, 15, 80, 98, 84, 44, 57, 71, 90, 95, 24, 66, 47, 36, 80, 99, 88, 28, 86, 85, 34, 30, 38, 63, 57, 99, 95, 32, 62, 16, 96, 96, 81, 15, 55, 75, 74, 60, 30, 35, 94, 76, 94, 69, 69, 61, 15, 93, 48, 40, 52, 25, 63, 29, 33, 65, 23, 87, 82, 84, 91, 32, 32, 14, 97, 62, 89, 57, 36, 23, 70, 83, 83, 13, 44, 95, 26, 75, 70, 14, 35, 16, 68, 81, 78, 27, 35, 81, 53, 22, 96, 63, 68, 26, 67, 21, 58, 93, 21, 88, 78, 76, 74, 97, 58, 23, 74, 73, 74, 27, 96, 95, 27, 67, 83, 66, 50, 28, 20, 99, 56, 53, 33, 67, 93, 73, 61, 64, 18, 46, 32, 95, 86, 86, 50, 46, 23, 31, 16, 63, 75, 31, 74, 77, 48, 32, 40, 67, 32, 28, 16, 98, 79, 93, 54, 70, 56, 99, 46, 43, 100, 16, 66, 37, 24, 80, 76, 62, 55, 96, 98, 90, 94, 75, 32, 73, 47, 37, 76, 92, 75, 50, 91, 85, 42, 94, 100, 30, 25, 98, 69, 15, 19, 63, 38, 92, 93, 68, 99, 75, 78, 91, 66, 25, 42, 88, 54, 75, 91, 87, 77, 83, 43, 44, 26, 50, 24, 48, 73, 44, 43, 61, 67, 95, 39, 100, 96, 21, 33, 82, 96, 15, 69, 52, 65, 80, 53, 95, 81, 77, 14, 78, 77, 74, 66, 81, 72, 39, 32, 95, 21, 37, 43, 23, 13, 26, 43, 74, 15, 80, 38, 34, 84, 77, 87, 100, 26, 43, 66, 79, 74, 78, 88, 73, 67, 87, 30, 41, 42, 40, 46, 20, 34, 61, 29, 52, 45, 79, 66, 73, 44, 76, 38, 79, 34, 69, 69, 39, 80, 78, 77, 65, 88, 41, 26, 69, 60, 49, 38, 23, 88, 89, 74, 25, 44, 70, 40, 65, 71, 50, 75, 100, 84, 82, 93, 82, 99, 98, 93, 24, 36, 17, 80, 97, 70, 34, 41, 69, 86, 65, 48, 53, 38, 83, 77, 88, 54, 23, 95, 87, 24, 96, 99, 92, 50, 27, 67, 79, 70, 78, 63, 30, 33, 20, 100, 91, 50, 86, 85, 52, 18, 76, 29, 55, 28, 35, 44, 73, 76, 20, 41, 82, 17, 94, 73, 74, 98, 62, 65, 89, 26, 75, 80, 62, 71, 61, 39, 73, 46, 13, 58, 72, 49, 96, 35, 98, 60, 13, 73, 50, 46, 75, 88, 81, 74, 86, 99, 99, 25, 63, 69, 100, 86, 90, 73, 78, 60, 71, 30, 69, 23, 92, 65, 31, 93, 72, 95, 67, 93, 32, 74, 100, 78, 43, 23, 94, 88, 21, 73, 57, 29, 46, 100, 66, 64, 18, 69, 40, 31, 34, 64, 61, 66, 32, 67, 93, 59, 85, 85, 77, 44, 30, 20, 40, 90, 88, 84, 85, 26, 48, 25, 50, 43, 92, 33, 13, 37, 67, 97, 61, 89, 46, 100, 97, 61, 65, 34, 84, 20, 97, 80, 25, 96, 98, 65, 61, 28, 84, 55, 72, 15, 30, 96, 66, 18, 83, 95, 20, 52, 65, 97, 19, 78, 31, 38, 40, 100, 23, 38, 22, 35, 20, 63, 32, 85, 96, 58, 37, 88, 53, 90, 64, 51, 91, 46, 46, 83, 58, 91, 18, 89, 71, 65, 66, 92, 47, 14, 47, 72, 49, 99, 73, 86, 68, 100, 52, 100, 27, 26, 97, 61, 29, 62, 30, 68, 69, 76, 74, 13, 20, 32, 92, 14, 57, 98, 42, 54, 71, 40, 98, 81, 88, 65, 96, 46, 39, 50, 47, 60, 54, 84, 67, 47, 31, 74, 63, 26, 24, 74, 77, 13, 28, 69, 15, 73, 42, 93, 74, 81, 89, 74, 95, 55, 44, 20, 13, 94, 78, 63, 43, 23, 22, 13, 28, 55, 85, 76, 45, 88, 64, 84, 14, 50, 39, 60, 69, 43, 14, 20, 98, 47, 51, 44, 67, 76, 98, 99, 23, 75, 39, 73, 13, 87, 41, 60, 97, 47, 42, 60, 64, 97, 40, 19, 96, 67, 65, 80, 28, 91, 13, 15, 59, 91, 63, 83, 48, 92, 65, 88, 88, 70, 37, 13, 57, 89, 23, 15, 22, 37, 70, 43, 80, 70, 77, 89, 25, 31, 39, 86, 49, 24, 32, 22, 97, 26, 44, 97, 38, 47, 73, 16, 19, 69, 67, 80, 88, 73, 70] [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    train_X.append(randint(13, 64))\n",
    "    train_Y.append(1)\n",
    "    train_X.append(randint(65, 100))\n",
    "    train_Y.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    train_X.append(randint(13, 64))\n",
    "    train_Y.append(0)\n",
    "    train_X.append(randint(65, 100))\n",
    "    train_Y.append(1)\n",
    "    \n",
    "train_X, train_Y=shuffle(train_X, train_Y)\n",
    "\n",
    "    \n",
    "print(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=np.array(train_X)\n",
    "train_Y=np.array(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14942529]\n",
      " [0.49425287]\n",
      " [0.96551724]\n",
      " ...\n",
      " [0.86206897]\n",
      " [0.68965517]\n",
      " [0.65517241]]\n"
     ]
    }
   ],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_X=scaler.fit_transform(train_X.reshape(-1, 1))\n",
    "print(scaled_train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation=\"relu\"),\n",
    "    Dense(units=32, activation=\"relu\"),\n",
    "    Dense(units=2, activation=\"sigmoid\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0003), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "56/56 - 3s - loss: 0.7821 - accuracy: 0.4631 - val_loss: 0.7604 - val_accuracy: 0.4119\n",
      "Epoch 2/30\n",
      "56/56 - 0s - loss: 0.7402 - accuracy: 0.3595 - val_loss: 0.7233 - val_accuracy: 0.3024\n",
      "Epoch 3/30\n",
      "56/56 - 0s - loss: 0.7058 - accuracy: 0.3256 - val_loss: 0.6905 - val_accuracy: 0.6190\n",
      "Epoch 4/30\n",
      "56/56 - 0s - loss: 0.6758 - accuracy: 0.6607 - val_loss: 0.6598 - val_accuracy: 0.6905\n",
      "Epoch 5/30\n",
      "56/56 - 0s - loss: 0.6475 - accuracy: 0.7089 - val_loss: 0.6327 - val_accuracy: 0.7286\n",
      "Epoch 6/30\n",
      "56/56 - 0s - loss: 0.6219 - accuracy: 0.7488 - val_loss: 0.6059 - val_accuracy: 0.7690\n",
      "Epoch 7/30\n",
      "56/56 - 0s - loss: 0.5952 - accuracy: 0.7821 - val_loss: 0.5778 - val_accuracy: 0.7976\n",
      "Epoch 8/30\n",
      "56/56 - 0s - loss: 0.5673 - accuracy: 0.8095 - val_loss: 0.5486 - val_accuracy: 0.8286\n",
      "Epoch 9/30\n",
      "56/56 - 0s - loss: 0.5386 - accuracy: 0.8268 - val_loss: 0.5187 - val_accuracy: 0.8524\n",
      "Epoch 10/30\n",
      "56/56 - 0s - loss: 0.5096 - accuracy: 0.8399 - val_loss: 0.4892 - val_accuracy: 0.8571\n",
      "Epoch 11/30\n",
      "56/56 - 0s - loss: 0.4812 - accuracy: 0.8577 - val_loss: 0.4605 - val_accuracy: 0.8643\n",
      "Epoch 12/30\n",
      "56/56 - 0s - loss: 0.4540 - accuracy: 0.8702 - val_loss: 0.4334 - val_accuracy: 0.8714\n",
      "Epoch 13/30\n",
      "56/56 - 0s - loss: 0.4286 - accuracy: 0.8804 - val_loss: 0.4084 - val_accuracy: 0.8810\n",
      "Epoch 14/30\n",
      "56/56 - 0s - loss: 0.4054 - accuracy: 0.8893 - val_loss: 0.3856 - val_accuracy: 0.8881\n",
      "Epoch 15/30\n",
      "56/56 - 0s - loss: 0.3845 - accuracy: 0.8958 - val_loss: 0.3652 - val_accuracy: 0.8881\n",
      "Epoch 16/30\n",
      "56/56 - 0s - loss: 0.3659 - accuracy: 0.9000 - val_loss: 0.3473 - val_accuracy: 0.8952\n",
      "Epoch 17/30\n",
      "56/56 - 0s - loss: 0.3497 - accuracy: 0.9065 - val_loss: 0.3317 - val_accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "56/56 - 0s - loss: 0.3357 - accuracy: 0.9113 - val_loss: 0.3182 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "56/56 - 0s - loss: 0.3237 - accuracy: 0.9173 - val_loss: 0.3067 - val_accuracy: 0.9143\n",
      "Epoch 20/30\n",
      "56/56 - 0s - loss: 0.3135 - accuracy: 0.9202 - val_loss: 0.2968 - val_accuracy: 0.9143\n",
      "Epoch 21/30\n",
      "56/56 - 0s - loss: 0.3048 - accuracy: 0.9226 - val_loss: 0.2884 - val_accuracy: 0.9286\n",
      "Epoch 22/30\n",
      "56/56 - 0s - loss: 0.2975 - accuracy: 0.9226 - val_loss: 0.2813 - val_accuracy: 0.9286\n",
      "Epoch 23/30\n",
      "56/56 - 0s - loss: 0.2912 - accuracy: 0.9238 - val_loss: 0.2751 - val_accuracy: 0.9286\n",
      "Epoch 24/30\n",
      "56/56 - 0s - loss: 0.2858 - accuracy: 0.9262 - val_loss: 0.2698 - val_accuracy: 0.9286\n",
      "Epoch 25/30\n",
      "56/56 - 0s - loss: 0.2812 - accuracy: 0.9292 - val_loss: 0.2653 - val_accuracy: 0.9286\n",
      "Epoch 26/30\n",
      "56/56 - 0s - loss: 0.2773 - accuracy: 0.9310 - val_loss: 0.2614 - val_accuracy: 0.9357\n",
      "Epoch 27/30\n",
      "56/56 - 0s - loss: 0.2739 - accuracy: 0.9327 - val_loss: 0.2580 - val_accuracy: 0.9357\n",
      "Epoch 28/30\n",
      "56/56 - 0s - loss: 0.2709 - accuracy: 0.9333 - val_loss: 0.2551 - val_accuracy: 0.9357\n",
      "Epoch 29/30\n",
      "56/56 - 0s - loss: 0.2684 - accuracy: 0.9351 - val_loss: 0.2525 - val_accuracy: 0.9357\n",
      "Epoch 30/30\n",
      "56/56 - 0s - loss: 0.2661 - accuracy: 0.9351 - val_loss: 0.2503 - val_accuracy: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24fe3d98d60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_X, y=train_Y, validation_split=0.2, batch_size=30, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.array([ 35, 45, 99, 65, 72, 31, 67, 80,22,64])\n",
    "test_Y=np.array([0, 0, 1,1,1,0,1,1,0,0])\n",
    "test, test_Y=shuffle(test, test_Y)\n",
    "scaler_test=MinMaxScaler(feature_range=(0,1))\n",
    "test=scaler_test.fit_transform(test.reshape(-1, 1))\n",
    "prediction=model.predict(x=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8013257  0.1903511 ]\n",
      " [0.17654303 0.9114973 ]\n",
      " [0.5621213  0.49427846]\n",
      " [0.80357957 0.18913856]\n",
      " [0.5453497  0.5148545 ]\n",
      " [0.304283   0.78544897]\n",
      " [0.5115343  0.5557868 ]\n",
      " [0.42721117 0.65377915]\n",
      " [0.7987236  0.19354564]\n",
      " [0.79200375 0.20136777]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "rounded_pred=(np.argmax(prediction, axis=1))\n",
    "print(rounded_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_true=test_Y, y_pred=rounded_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5 0]\n",
      " [1 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=[\"No side affets\", \"side effects\"]\n",
    "plot_confusion_matrix(cm=cm, classes=classes, title=\"cm \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model=load_model(\"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.38786834,  0.27928093,  0.21978931, -0.38418895, -0.48554552,\n",
       "         -0.03112239,  0.6862441 ,  0.7044105 ,  0.43674496,  0.62935495,\n",
       "          0.50059676,  0.49435648, -0.07111096,  0.0257336 , -0.48399156,\n",
       "         -0.03798974]], dtype=float32),\n",
       " array([-0.1327784 , -0.09487563,  0.2740901 ,  0.        ,  0.        ,\n",
       "         0.        , -0.17757377, -0.21527384, -0.1384906 ,  0.30069417,\n",
       "        -0.16539247, -0.15558727,  0.        , -0.02643446,  0.        ,\n",
       "         0.        ], dtype=float32),\n",
       " array([[ 0.28412107,  0.07918049, -0.3751665 , -0.22319943, -0.08087602,\n",
       "         -0.13601455, -0.34037957,  0.24416374, -0.26858687,  0.2871972 ,\n",
       "         -0.16353507, -0.43525442,  0.5659579 ,  0.18908827,  0.07254367,\n",
       "          0.12863445, -0.06660458,  0.0685156 , -0.15740483, -0.6233055 ,\n",
       "         -0.10696059,  0.2604686 , -0.30181104, -0.34815183,  0.7225273 ,\n",
       "         -0.18331097,  0.5640359 ,  0.5454203 ,  0.12185365, -0.06197317,\n",
       "         -0.15317707,  0.30431423],\n",
       "        [ 0.2934819 , -0.42392474, -0.30440426, -0.11837801,  0.0876988 ,\n",
       "         -0.3081946 ,  0.01803439, -0.1255641 ,  0.33216393, -0.35437107,\n",
       "         -0.27068573, -0.39310184,  0.19028766, -0.34511966, -0.44623503,\n",
       "          0.34716398, -0.41330025, -0.3389915 , -0.10125265, -0.23363265,\n",
       "          0.03093614,  0.07524899,  0.32796305, -0.18621953,  0.5981303 ,\n",
       "          0.03379157,  0.06041821,  0.5253296 ,  0.17257303, -0.15193373,\n",
       "          0.06110594, -0.05277088],\n",
       "        [ 0.20705041, -0.22472002,  0.17987034, -0.32014823,  0.05683294,\n",
       "         -0.34067193, -0.05223919, -0.21777517, -0.13012694, -0.29127705,\n",
       "          0.06295391,  0.38371804, -0.02016534,  0.15215148, -0.38647485,\n",
       "          0.14097066,  0.30076185, -0.28457257,  0.2003226 , -0.10199607,\n",
       "          0.45343477, -0.30250072, -0.05455332, -0.01288286, -0.04937579,\n",
       "         -0.30212176, -0.1304524 ,  0.16695216,  0.2916255 , -0.21431856,\n",
       "         -0.14201954, -0.13587192],\n",
       "        [ 0.26002076, -0.1761348 ,  0.24531117, -0.3118012 , -0.3274961 ,\n",
       "          0.29830828, -0.31090406, -0.13851579, -0.32813665, -0.07532594,\n",
       "          0.04146019, -0.06503293, -0.2718744 , -0.33446214, -0.12504236,\n",
       "          0.2683163 ,  0.19813648, -0.25534725,  0.19279149, -0.15710457,\n",
       "         -0.19100395, -0.03991744, -0.08513671,  0.04961881,  0.09336767,\n",
       "         -0.3016932 ,  0.16707805, -0.10698067,  0.09924075,  0.2612755 ,\n",
       "          0.15039983, -0.16900119],\n",
       "        [ 0.04937461, -0.02805421, -0.10335234,  0.33161226,  0.02231389,\n",
       "         -0.0972724 , -0.31542128,  0.34221485, -0.16412851,  0.22322515,\n",
       "          0.12971568,  0.09825754, -0.11594801, -0.22955357,  0.3222656 ,\n",
       "          0.26903823,  0.11548573, -0.091409  ,  0.23629907,  0.08658868,\n",
       "          0.00524339,  0.04872739,  0.10352978, -0.21203792, -0.14188442,\n",
       "          0.12797654,  0.26061848, -0.30710858, -0.00310859, -0.09326413,\n",
       "          0.05763969, -0.2167571 ],\n",
       "        [-0.04640546,  0.32826462,  0.13827538, -0.06585023,  0.24958065,\n",
       "         -0.10325009,  0.09656662, -0.22008435, -0.03563347, -0.10577932,\n",
       "         -0.08382097, -0.27219808, -0.21445994,  0.19468525, -0.00784099,\n",
       "          0.15439013,  0.03784779,  0.31406912, -0.07699731, -0.10245225,\n",
       "         -0.02155188, -0.22211389, -0.27465913, -0.29575235,  0.21817425,\n",
       "         -0.05459046,  0.21609506, -0.15840784, -0.11741176,  0.2930064 ,\n",
       "          0.11246869,  0.26242498],\n",
       "        [ 0.32510215,  0.19683263,  0.17905459, -0.01185128,  0.03801564,\n",
       "          0.31810135, -0.00178892, -0.04857135, -0.3000026 ,  0.11423533,\n",
       "         -0.14034161,  0.22233835,  0.39147463,  0.26166654,  0.13271609,\n",
       "          0.64122754, -0.47641388, -0.09216556, -0.12358122, -0.02547462,\n",
       "         -0.3831453 , -0.02684564, -0.321073  , -0.12487075,  0.5730906 ,\n",
       "         -0.01622865,  0.5991672 ,  0.40354654,  0.14739992,  0.2308546 ,\n",
       "         -0.1848484 ,  0.0938907 ],\n",
       "        [ 0.56449866,  0.19934775,  0.08349577, -0.35243052, -0.20258972,\n",
       "         -0.34281418, -0.5682452 ,  0.11818366,  0.04315931,  0.19511789,\n",
       "          0.06353121, -0.19355483,  0.0914124 , -0.07764262,  0.18499309,\n",
       "          0.39347792, -0.5632201 ,  0.02496129, -0.13022567, -0.4722766 ,\n",
       "         -0.4478026 , -0.046168  ,  0.09022155, -0.22920999,  0.5964609 ,\n",
       "         -0.31999707,  0.49633232,  0.43455496,  0.28614637,  0.2459922 ,\n",
       "          0.03173852, -0.34395832],\n",
       "        [ 0.580049  ,  0.08036759,  0.13340263, -0.05753449,  0.3096877 ,\n",
       "          0.3358942 , -0.25251415, -0.11916727, -0.21725933, -0.26826102,\n",
       "          0.22827889, -0.29766753,  0.5938152 , -0.17680807, -0.00126775,\n",
       "          0.4048276 , -0.03334684, -0.20847794,  0.00173071, -0.14097245,\n",
       "         -0.24159478,  0.25310034, -0.3436363 ,  0.20990333,  0.06889514,\n",
       "          0.18211326,  0.23016323,  0.28085807,  0.2389737 , -0.0303588 ,\n",
       "          0.12655443,  0.19967017],\n",
       "        [ 0.0703253 ,  0.01908319,  0.20340829, -0.31522918, -0.12278282,\n",
       "          0.10283792,  0.15031251, -0.0573604 , -0.2180816 ,  0.03254945,\n",
       "         -0.13769577, -0.08916309,  0.3378288 , -0.30982342,  0.2605242 ,\n",
       "         -0.08045136,  0.23437794, -0.02174702, -0.20739536,  0.24740265,\n",
       "         -0.01386374, -0.09976138, -0.12848885, -0.27025622,  0.25686836,\n",
       "         -0.22258441,  0.3895178 ,  0.3682439 , -0.28007242, -0.3025454 ,\n",
       "         -0.17558369, -0.1933447 ],\n",
       "        [ 0.05301014,  0.1759671 , -0.31642413,  0.17109713, -0.27024952,\n",
       "         -0.10480744, -0.59605944,  0.09757339, -0.3149966 , -0.10069549,\n",
       "          0.25660807, -0.39855576,  0.5526452 ,  0.31799656, -0.38720742,\n",
       "          0.02380388, -0.3643488 ,  0.27658972,  0.11734045, -0.31903338,\n",
       "         -0.48879534,  0.33489996, -0.00497231, -0.34317017,  0.56075007,\n",
       "         -0.16371058,  0.31746665,  0.59606624, -0.30044338, -0.03524246,\n",
       "         -0.2335496 , -0.02653313],\n",
       "        [ 0.2502818 , -0.2482946 , -0.24886146, -0.05896065,  0.25474116,\n",
       "          0.05923161, -0.08025166,  0.18977499,  0.2095742 ,  0.15442811,\n",
       "         -0.0675323 ,  0.09190735,  0.4066589 ,  0.0460007 ,  0.228009  ,\n",
       "          0.6694286 , -0.50581425,  0.02682209, -0.17021316, -0.34005696,\n",
       "         -0.30178922, -0.09927773,  0.15772638,  0.17304543,  0.29236063,\n",
       "         -0.27185786,  0.36018738,  0.08758534, -0.3838768 ,  0.2744541 ,\n",
       "         -0.11198173,  0.29697326],\n",
       "        [ 0.34635338, -0.29761195,  0.08377546, -0.33823395, -0.14655757,\n",
       "         -0.14569516, -0.30232263,  0.05864   ,  0.05863023, -0.2792775 ,\n",
       "          0.23414978, -0.01480752,  0.31480232, -0.01776296, -0.32194215,\n",
       "          0.28352574, -0.33176666,  0.08346045, -0.07482448, -0.13347974,\n",
       "          0.00836936, -0.1323636 , -0.2924038 , -0.08971024, -0.13319458,\n",
       "         -0.0227555 ,  0.19912621,  0.24242339,  0.18522611, -0.2748853 ,\n",
       "         -0.28354427,  0.34217677],\n",
       "        [-0.30712345,  0.32992676,  0.16269355,  0.21112606,  0.2818937 ,\n",
       "          0.17804858,  0.04059527, -0.27738783,  0.29401335, -0.3370515 ,\n",
       "          0.2552226 , -0.15557748,  0.26105818,  0.21415754, -0.066299  ,\n",
       "         -0.19720858,  0.15244474, -0.04558113,  0.1974242 , -0.11694533,\n",
       "         -0.2506055 ,  0.34701928, -0.2134581 ,  0.23679033,  0.3374421 ,\n",
       "         -0.04873279, -0.17158525,  0.13578299,  0.13030843, -0.02303661,\n",
       "          0.28682145,  0.24913278],\n",
       "        [ 0.0893198 ,  0.28163728,  0.14465809,  0.26204517, -0.17330825,\n",
       "         -0.30613616,  0.22956207,  0.3412759 , -0.31417787, -0.01481992,\n",
       "         -0.3047507 ,  0.20003441, -0.12537289,  0.32778212,  0.21248803,\n",
       "         -0.25220346, -0.23371187,  0.34817138, -0.1245447 ,  0.10111257,\n",
       "         -0.25535047,  0.2914898 , -0.15442209,  0.02233168,  0.16348013,\n",
       "         -0.21025874,  0.1810945 , -0.15912795,  0.05723938, -0.24858236,\n",
       "         -0.27557775, -0.31896725],\n",
       "        [ 0.32626584,  0.27256367, -0.05552214,  0.03737995,  0.34657428,\n",
       "          0.32581612,  0.22242466,  0.22216883, -0.32361048,  0.33179417,\n",
       "         -0.04268008, -0.02875629,  0.2731664 , -0.2207668 , -0.23364021,\n",
       "          0.08202636, -0.16188537, -0.21499874,  0.2963527 , -0.34733108,\n",
       "          0.1272785 , -0.16133687,  0.28779295, -0.21130937, -0.03798568,\n",
       "         -0.30177826, -0.1089952 , -0.00263798, -0.08001596, -0.2485553 ,\n",
       "          0.06339121,  0.07031569]], dtype=float32),\n",
       " array([-0.12559743, -0.06682047,  0.11082042,  0.        , -0.00918593,\n",
       "        -0.00583503,  0.3467414 , -0.00644623, -0.00275125, -0.00865925,\n",
       "        -0.01228535,  0.10283971, -0.1471062 , -0.01881731, -0.07127904,\n",
       "        -0.07043611,  0.34961602,  0.        ,  0.        ,  0.32573664,\n",
       "         0.35740587, -0.0072431 , -0.00505879,  0.        , -0.12928846,\n",
       "         0.        , -0.1502677 , -0.19603768, -0.05853689, -0.03793537,\n",
       "         0.        ,  0.        ], dtype=float32),\n",
       " array([[ 0.00703384,  0.5159804 ],\n",
       "        [ 0.3301423 ,  0.04156167],\n",
       "        [ 0.2309975 , -0.2853622 ],\n",
       "        [ 0.3390306 ,  0.204963  ],\n",
       "        [-0.19938004, -0.11062489],\n",
       "        [ 0.3118691 ,  0.3734552 ],\n",
       "        [ 0.9183146 , -0.30221117],\n",
       "        [ 0.32573506,  0.20283103],\n",
       "        [-0.17316929, -0.17424919],\n",
       "        [-0.02312797, -0.3967699 ],\n",
       "        [-0.10111993, -0.29159853],\n",
       "        [ 0.4867705 ,  0.18042561],\n",
       "        [-0.41743034,  0.3432991 ],\n",
       "        [ 0.15782407,  0.00985271],\n",
       "        [-0.1451393 , -0.26073697],\n",
       "        [-0.46319047,  0.31883365],\n",
       "        [ 0.36611304, -0.8551051 ],\n",
       "        [-0.03549734,  0.3001434 ],\n",
       "        [-0.1562975 , -0.17470594],\n",
       "        [ 0.75424796, -0.747558  ],\n",
       "        [ 0.5030962 , -0.7941843 ],\n",
       "        [ 0.31304574, -0.37477958],\n",
       "        [-0.34778705, -0.09274444],\n",
       "        [-0.41477478,  0.32555315],\n",
       "        [-0.3915915 ,  0.23946376],\n",
       "        [ 0.07074067,  0.3484743 ],\n",
       "        [ 0.04872184,  0.74077463],\n",
       "        [-0.3612692 ,  0.23280138],\n",
       "        [ 0.01870643, -0.27099353],\n",
       "        [ 0.14445925, -0.13501655],\n",
       "        [ 0.25442508, -0.33383453],\n",
       "        [-0.28364635, -0.06888169]], dtype=float32),\n",
       " array([ 0.14601998, -0.14602   ], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
